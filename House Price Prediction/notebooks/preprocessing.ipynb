{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26484d55",
   "metadata": {},
   "source": [
    "### Overview — what preprocessing should do\n",
    "\n",
    "1. Clean obvious problems (IDs, wrong dtypes).\n",
    "\n",
    "2. Handle missing values safely (fit imputers on training data only).\n",
    "\n",
    "3. Engineer a few robust features (age, totals, flags).\n",
    "\n",
    "4. Encode categorical variables (ordinal vs nominal).\n",
    "\n",
    "5. Handle skewed numeric features (log1p when needed).\n",
    "\n",
    "6. Scale if required (for linear models).\n",
    "\n",
    "7. Build a single sklearn Pipeline/ColumnTransformer that does everything reproducibly.\n",
    "\n",
    "8. Save the fitted pipeline for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c813e30",
   "metadata": {},
   "source": [
    "## 0 — Imports and load (start in a notebook/script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e483eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da524d46",
   "metadata": {},
   "source": [
    "## 1 — Quick cleanup & target transformation\n",
    "\n",
    "####  Why: remove non-features and stabilise the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb576667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "# drop Id (not a feature)\n",
    "if 'Id' in df.columns:\n",
    "    df = df.drop(columns=['Id'])\n",
    "\n",
    "# If target is skewed, log-transform for training stability\n",
    "df['SalePrice_log'] = np.log1p(df['price'])\n",
    "y = df['SalePrice_log']\n",
    "X = df.drop(columns=['price', 'SalePrice_log'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebaba1",
   "metadata": {},
   "source": [
    "### 2 — Decide column groups (programmatic)\n",
    "\n",
    "##### Why: separate numeric, ordinal, nominal for different transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32341b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "# optionally remove year columns from numeric if you will create age features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4e585",
   "metadata": {},
   "source": [
    "### 3 — Custom feature engineering transformer\n",
    "\n",
    "#### Why: create features like TotalSF, HouseAge, HasPool reproducibly inside the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262441d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Example engineered features\n",
    "        X['TotalSF'] = X['TotalBsmtSF'].fillna(0) + X['1stFlrSF'].fillna(0) + X['2ndFlrSF'].fillna(0) + X['GrLivArea'].fillna(0)\n",
    "        X['TotalBath'] = X['FullBath'].fillna(0) + 0.5 * X['HalfBath'].fillna(0) + X.get('BsmtFullBath', 0).fillna(0) + 0.5 * X.get('BsmtHalfBath', 0).fillna(0)\n",
    "        X['HouseAge'] = X['YrSold'] - X['YearBuilt']\n",
    "        X['RemodAge'] = X['YrSold'] - X['YearRemodAdd']\n",
    "        X['HasPool'] = (X['PoolArea'].fillna(0) > 0).astype(int)\n",
    "        X['HasGarage'] = (X['GarageArea'].fillna(0) > 0).astype(int)\n",
    "        X['HasBsmt'] = (X['TotalBsmtSF'].fillna(0) > 0).astype(int)\n",
    "        # add more engineered features as needed\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec1d2c",
   "metadata": {},
   "source": [
    "### 4 — Missing value strategy (rules & implementation)\n",
    "\n",
    " Why: different semantics need different imputations.\n",
    "\n",
    "* If missing means none (e.g., PoolQC, GarageType) → fill 'None'.\n",
    "\n",
    "* If numerical structural missingness (e.g., LotFrontage) → impute by group median (Neighborhood).\n",
    "\n",
    "* Numeric random missing → median.\n",
    "\n",
    "* For features where missing might be predictive, create a missing indicator column.\n",
    "\n",
    "Implementation inside pipeline: use SimpleImputer and a small custom transformer for groupwise fills if needed.\n",
    "\n",
    "Example for groupwise fill (outside pipeline or inside a transformer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e7941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lotfrontage_by_neighborhood(df):\n",
    "    df = df.copy()\n",
    "    df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82732c",
   "metadata": {},
   "source": [
    "### 5 — Ordinal encoding for quality-like features\n",
    "\n",
    "Why: ExterQual, KitchenQual, BsmtQual are ordered; map them to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbd608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_map = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, np.nan:0}\n",
    "# In pipeline you can use sklearn's OrdinalEncoder with custom categories order,\n",
    "# but a mapping in FeatureEngineer or a small transformer is simpler.\n",
    "class OrdinalMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mappings):\n",
    "        self.mappings = mappings\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, m in self.mappings.items():\n",
    "            if col in X.columns:\n",
    "                X[col + \"_num\"] = X[col].map(m).fillna(0)\n",
    "        return X\n",
    "\n",
    "ord_mappings = {\n",
    "    'ExterQual': {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1},\n",
    "    'KitchenQual': {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1},\n",
    "    'BsmtQual': {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfcf97",
   "metadata": {},
   "source": [
    "### 6 — Nominal (high-cardinality) categorical encoding\n",
    "\n",
    "Options & recommendation:\n",
    "\n",
    "Low-cardinality (<= ~10 unique): One-Hot encode.\n",
    "\n",
    "High-cardinality (Neighborhood, etc.): Frequency encoding or target (mean) encoding with CV-safe implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f16b25",
   "metadata": {},
   "source": [
    "Frequency encoding example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e67d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encode(series):\n",
    "    freq = series.value_counts() / len(series)\n",
    "    return series.map(freq)\n",
    "\n",
    "# In pipeline: implement as transformer or do before pipeline and treat as numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617241a",
   "metadata": {},
   "source": [
    "Safe target encoding (out-of-fold) — sketch (use KFold on training only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ecb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_mean_encode_train(X, y, col, n_splits=5):\n",
    "    X = X.copy()\n",
    "    X[col + \"_te\"] = np.nan\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for tr_idx, val_idx in kf.split(X):\n",
    "        tr_mean = X.iloc[tr_idx].groupby(col)[y.name].mean()\n",
    "        X.loc[X.index[val_idx], col + \"_te\"] = X.loc[X.index[val_idx]][col].map(tr_mean)\n",
    "    # global mean for any unseen categories\n",
    "    global_mean = y.mean()\n",
    "    X[col + \"_te\"].fillna(global_mean, inplace=True)\n",
    "    return X[col + \"_te\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f96853",
   "metadata": {},
   "source": [
    "### 7 — Skewness & numeric transforms\n",
    "\n",
    "Why: many area/price-like columns are right-skewed — log1p helps linear models and stabilises variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80beb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find skewed numeric features\n",
    "skewness = X[num_cols].apply(lambda s: s.dropna().skew()).sort_values(ascending=False)\n",
    "skewed_feats = skewness[abs(skewness) > 0.75].index.tolist()\n",
    "\n",
    "# transform them (inside pipeline use FunctionTransformer)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=False)\n",
    "# apply log_transformer to skewed numeric columns only in ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ea1f1",
   "metadata": {},
   "source": [
    "### 8 — Outlier handling\n",
    "\n",
    "Options:\n",
    "\n",
    "Remove extreme obvious errors (e.g., GrLivArea > 4500 may be data error) — do only after inspection.\n",
    "\n",
    "Clip/winsorize numeric features.\n",
    "\n",
    "Use robust models (tree-based) that tolerate outliers.\n",
    "\n",
    "Example to clip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f12d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_outliers(X, columns, lower_quantile=0.01, upper_quantile=0.99):\n",
    "    X = X.copy()\n",
    "    for col in columns:\n",
    "        lo = X[col].quantile(lower_quantile)\n",
    "        hi = X[col].quantile(upper_quantile)\n",
    "        X[col] = X[col].clip(lo, hi)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1b062",
   "metadata": {},
   "source": [
    "### 9 — Scaling\n",
    "\n",
    "Tree models (XGBoost, RandomForest): no scaling needed.\n",
    "\n",
    "Linear models / KNN / SVM: use StandardScaler or RobustScaler (better with outliers).\n",
    "\n",
    "Include scaling in numeric pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd6cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(np.log1p, validate=False)),  # optional: only on skewed subset\n",
    "    ('scaler', StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03bed1",
   "metadata": {},
   "source": [
    "### 10 — Putting it together — example ColumnTransformer pipeline\n",
    "\n",
    "This example demonstrates a full pipeline including feature engineering, ordinal mapping, numeric & categorical processing. Adjust lists to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0697219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns (example)\n",
    "numeric_features = ['LotFrontage','LotArea','OverallQual','GrLivArea','TotalBsmtSF','1stFlrSF','2ndFlrSF','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd']\n",
    "ordinal_features = ['ExterQual','KitchenQual','BsmtQual']  # map separately\n",
    "low_card_cat = ['MSZoning','Street','SaleCondition']  # one-hot\n",
    "high_card_cat = ['Neighborhood']  # freq/target encode\n",
    "\n",
    "# Pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())   # or omitted for trees\n",
    "])\n",
    "\n",
    "cat_low_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# combine into ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat_low', cat_low_pipeline, low_card_cat),\n",
    "    # For ordinal and high-cardinality, we'll handle in FeatureEngineer/OrdinalMapper or as separate pipeline pieces\n",
    "], remainder='passthrough') # remainder will let FeatureEngineer output flow through\n",
    "\n",
    "# Full pipeline with custom feature engineering & ordinal mapping BEFORE ColumnTransformer\n",
    "full_pipeline = Pipeline([\n",
    "    ('feat_eng', FeatureEngineer()),\n",
    "    ('ordinal', OrdinalMapper(ord_mappings)),\n",
    "    ('preproc', preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d54f8",
   "metadata": {},
   "source": [
    "# 11 — Fit on training, transform test safely\n",
    "\n",
    "Always fit the pipeline only on training data and transform validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)         # fit imputers, scalers, etc.\n",
    "X_train_trans = full_pipeline.transform(X_train)\n",
    "X_valid_trans = full_pipeline.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecd072",
   "metadata": {},
   "source": [
    "### 12 — Save pipeline & metadata\n",
    "\n",
    "Save the fitted pipeline (and any mapping dicts) for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(full_pipeline, \"models/preprocessor.joblib\")\n",
    "# Save ordinal mapping too (if used externally)\n",
    "joblib.dump(ord_mappings, \"models/ordinal_mappings.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ddc25a",
   "metadata": {},
   "source": [
    "### Load in inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = joblib.load(\"models/preprocessor.joblib\")\n",
    "X_new = pd.read_csv(\"data/test.csv\")  # raw test\n",
    "X_new_transformed = preprocessor.transform(X_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
