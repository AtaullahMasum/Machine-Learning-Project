{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8234877f",
   "metadata": {},
   "source": [
    "### 1 — Pipeline (core)\n",
    "What it is\n",
    "\n",
    "A sequential container of transformers (all but last) and a final estimator. It chains transforms and a final fit/predict call so preprocessing + model act as one object.\n",
    "\n",
    "Constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(steps=[('name1', transformer1), ('name2', transformer2), ..., ('final', estimator)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317ccc8",
   "metadata": {},
   "source": [
    "steps: ordered list of (name, object) pairs.\n",
    "\n",
    "Names must be unique and valid identifiers.\n",
    "\n",
    "All steps except the last must implement .fit and .transform (or .fit_transform). The last must implement .fit and at least one of .predict, .transform, or .fit_transform depending on use.\n",
    "\n",
    "Key behavior (fit / transform / predict)\n",
    "\n",
    "pipe.fit(X, y):\n",
    "\n",
    "For each intermediate step t: call X = t.fit_transform(X, y) (if exists) or t.fit(X, y); X = t.transform(X).\n",
    "\n",
    "Call final.fit(X, y) on the transformed data.\n",
    "\n",
    "pipe.predict(X):\n",
    "\n",
    "Transform through all transformers (.transform) in order.\n",
    "\n",
    "Call final.predict(X_transformed).\n",
    "\n",
    "pipe.transform(X) works only if the final estimator has .transform (then pipeline returns final .transform output).\n",
    "\n",
    "pipe.fit_transform(X, y) is shorthand for fitting then transforming as above.\n",
    "\n",
    "Important methods & what they do\n",
    "\n",
    ".fit(X, y=None, **fit_params) — fit pipeline on data.\n",
    "\n",
    ".fit_transform(X, y=None, **fit_params) — convenience.\n",
    "\n",
    ".transform(X) — apply pipeline transforms up to final step; final must implement .transform.\n",
    "\n",
    ".predict(X) — transform then final .predict.\n",
    "\n",
    ".predict_proba(X) / .decision_function(X) — delegated to final estimator if supported.\n",
    "\n",
    ".score(X, y) — delegated to final estimator’s .score after transforming X.\n",
    "\n",
    ".get_params(deep=True) — returns all parameters including nested (used by GridSearchCV). Parameter names use step__param notation.\n",
    "\n",
    ".set_params(**params) — set params; use nested names e.g. preproc__num__imputer__strategy='median'.\n",
    "\n",
    ".named_steps — dict-like: access a step by name: pipe.named_steps['preproc'].\n",
    "\n",
    ".steps — list of (name, estimator) pairs in order.\n",
    "\n",
    "Attributes created after fit\n",
    "\n",
    "pipe.named_steps['step_name'] is the fitted transformer/estimator instance.\n",
    "\n",
    "If the final estimator exposes attributes (e.g., coef_), access pipe.named_steps['final'].coef_. (Alternatively use pipe.named_steps['final'] or pipe itself after fit in sklearn 1.0+ via delegation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bac033",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline(steps=..., memory='cache_dir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08963f10",
   "metadata": {},
   "source": [
    "Caches results of transformer fit_transform calls to speed repeated calls (useful in GridSearch).\n",
    "\n",
    "Requires that transformer objects be picklable. Use for expensive transforms.\n",
    "\n",
    "verbose argument\n",
    "\n",
    "If True, prints pipeline progress during fit.\n",
    "\n",
    "Example: simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea4736",
   "metadata": {},
   "source": [
    "### 2 — make_pipeline (helper)\n",
    "What\n",
    "\n",
    "Convenience constructor that gives automatic step names based on class names (lowercased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f22fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(SimpleImputer(), StandardScaler(), Ridge())\n",
    "# step names: 'simpleimputer', 'standardscaler', 'ridge'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb598d",
   "metadata": {},
   "source": [
    "Use case\n",
    "\n",
    "When you don’t care about custom step names. Works identical to Pipeline.\n",
    "\n",
    "### 3 — FeatureUnion and make_union\n",
    "What\n",
    "\n",
    "Concatenate outputs of multiple transformer branches (horizontal concatenation). Useful when you want to apply different transforms to the same input and combine results (e.g., BOW + TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb395f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "union = FeatureUnion([\n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('select', SelectKBest(k=10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3e6c2",
   "metadata": {},
   "source": [
    "Behavior\n",
    "\n",
    "For each transformer, call .fit_transform(X), then horizontally stack outputs (numpy arrays or sparse matrices).\n",
    "\n",
    "Order in output respects the order you pass transformers.\n",
    "\n",
    "n_jobs supported to run transforms in parallel.\n",
    "\n",
    "make_union\n",
    "\n",
    "Like make_pipeline — auto names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "fu = FeatureUnion([('pca', PCA(n_components=5)), ('kbest', SelectKBest(k=5))])\n",
    "X_new = fu.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d396ec",
   "metadata": {},
   "source": [
    "### 4 — FunctionTransformer\n",
    "What\n",
    "\n",
    "Wraps an arbitrary function into a transformer so it can be used in pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ce823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_tr = FunctionTransformer(np.log1p, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f0fb8",
   "metadata": {},
   "source": [
    "validate=False lets you pass DataFrame input; set validate=True to enforce 2D numpy arrays.\n",
    "\n",
    "Implement custom inverse via inverse_func argument if you want to support .inverse_transform.\n",
    "\n",
    "Use case\n",
    "\n",
    "Quick transforms without writing a custom class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893a9ff",
   "metadata": {},
   "source": [
    "### 5 — Custom transformers (BaseEstimator + TransformerMixin)\n",
    "Why\n",
    "\n",
    "When you need domain-specific feature engineering or complex logic. Implementing fit and transform allows insertion into pipelines.\n",
    "\n",
    "Pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec84ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param=...): self.param = param\n",
    "    def fit(self, X, y=None):\n",
    "        # learn from X (store attributes)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # return transformed X (numpy array or DataFrame)\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbf6c6",
   "metadata": {},
   "source": [
    "### 6 — Integration with ColumnTransformer & pipeline patterns\n",
    "\n",
    "Usually you combine ColumnTransformer (apply different pipelines to different column sets) with a top-level Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "full_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b499e2",
   "metadata": {},
   "source": [
    "Then use full_pipe with fit / predict / GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3848702",
   "metadata": {},
   "source": [
    "### 7 — Pipeline methods in detail (practical list)\n",
    "\n",
    "1. fit(X, y=None, **fit_params) — fit all transformers and final estimator.\n",
    "\n",
    "2. fit_transform(X, y=None) — fit + transform up to (and including) last step if it’s a transformer; otherwise returns result from last transform.\n",
    "\n",
    "3. transform(X) — apply transforms only; final estimator must implement transform.\n",
    "\n",
    "4. predict(X) — transform then final predict.\n",
    "\n",
    "5. predict_proba(X), decision_function(X), etc. — delegated if final estimator supports.\n",
    "\n",
    "6. score(X, y) — delegated to final estimator’s score (after transform).\n",
    "\n",
    "7. set_params(**kwargs) — set nested params: pipeline__step__param=value.\n",
    "\n",
    "8. get_params(deep=True) — returns nested param dict.\n",
    "\n",
    "9. named_steps — access steps by name: pipe.named_steps['imputer'].\n",
    "\n",
    "10. steps — list of pairs.\n",
    "\n",
    "11. memory — cache directory or joblib.Memory for caching transformers fit results.\n",
    "\n",
    "12. verbose — prints details during fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e78408",
   "metadata": {},
   "source": [
    "### 8 — GridSearchCV & pipeline: parameter naming\n",
    "\n",
    "When tuning hyperparams inside a pipeline, use step__param:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'pre__num__imputer__strategy': ['median','mean'],\n",
    "    'model__alpha': [0.01, 0.1, 1.0]\n",
    "}\n",
    "gs = GridSearchCV(full_pipe, param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de7c6a",
   "metadata": {},
   "source": [
    "get_params() shows all available names — very useful for building param_grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ea63a",
   "metadata": {},
   "source": [
    "### 9 — Caching expensive steps\n",
    "\n",
    "If a transformer (e.g., expensive feature extraction) takes long and is reused across different parameter combinations, enable caching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8587671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('pre', preprocessor), ('clf', model)], memory='cache_dir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee506d",
   "metadata": {},
   "source": [
    "Cache stored under 'cache_dir'. To clear, delete that dir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89392be4",
   "metadata": {},
   "source": [
    "### 10 — Best practices & gotchas\n",
    "\n",
    "1. Fit only on training data: always fit pipeline on training set. Use pipeline inside cross-validation so imputation/encoding is learned per fold.\n",
    "\n",
    "2. Use handle_unknown='ignore' for OneHotEncoder to avoid errors on unseen categories.\n",
    "\n",
    "3. Final estimator must be last: if final step is a transformer, .predict won’t be available.\n",
    "\n",
    "4. Preserve feature names: ColumnTransformer.get_feature_names_out() helps map transformed columns back to names.\n",
    "\n",
    "5. Memory + non-picklable objects: caching requires picklable transformers.\n",
    "\n",
    "6. Avoid heavy nesting of parallelism: if model uses n_jobs=-1 and GridSearch also uses n_jobs=-1, you may oversubscribe CPUs.\n",
    "\n",
    "7. When pipelines return sparse matrices (e.g., many OHE features), ensure downstream estimator accepts sparse input (many do).\n",
    "\n",
    "8. Partial fit: pipelines can work with estimators that support partial_fit, but transformers must be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469dd52",
   "metadata": {},
   "source": [
    "### 11 — Short cheat-sheet examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da532389",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SimpleImputer(), StandardScaler(), Ridge())\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2685a78",
   "metadata": {},
   "source": [
    "Grid search over pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f850437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'ridge__alpha': [0.1, 1.0, 10.0]}\n",
    "gs = GridSearchCV(pipe, param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a715a85",
   "metadata": {},
   "source": [
    "Pipeline with ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da458eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer()), ('scaler', StandardScaler())])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(fill_value='None')), ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
    "full = Pipeline([('pre', pre), ('model', XGBRegressor())])\n",
    "full.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8e0c2",
   "metadata": {},
   "source": [
    "Access inner estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d36a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.named_steps['model'].feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b76471",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
