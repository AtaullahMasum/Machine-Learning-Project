{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94029df7",
   "metadata": {},
   "source": [
    "### What is Data Preprocessing?\n",
    "Data preprocessing is the process of cleaning, transforming, and preparing raw data before feeding it to a machine learning model.\n",
    "It ensures data quality, consistency, and better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4e31a",
   "metadata": {},
   "source": [
    "### üß© Main Steps of Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b26f9c",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£ Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87b599",
   "metadata": {},
   "source": [
    "Goal: Gather data from various sources.\n",
    "Examples of sources:\n",
    "\n",
    "Databases (SQL, MongoDB, etc.)\n",
    "\n",
    "CSV/Excel files\n",
    "\n",
    "APIs / Web scraping\n",
    "\n",
    "IoT sensors, logs, etc.\n",
    "\n",
    "Tools/Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fa581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")  # or pd.read_excel(), pd.read_json(), etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9c383",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Data Inspection & Exploration\n",
    "\n",
    "Goal: Understand the structure, quality, and characteristics of the data.\n",
    "\n",
    "Common Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1507f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()        # First 5 rows\n",
    "df.info()        # Data types and null values\n",
    "df.describe()    # Summary statistics\n",
    "df.shape         # Rows √ó Columns\n",
    "df.columns       # Feature names\n",
    "df.nunique()     # Unique values per column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c69181",
   "metadata": {},
   "source": [
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ed4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(df)\n",
    "sns.heatmap(df.corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e0030",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Handling Missing Values\n",
    "\n",
    "Goal: Handle incomplete or missing data properly.\n",
    "\n",
    "‚úÖ Methods:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7272684",
   "metadata": {},
   "source": [
    "| Method | Description | Example |\n",
    "|--------|-------------|---------|\n",
    "| Drop missing | Remove rows or columns with NaN | `df.dropna()` |\n",
    "| Imputation (Mean/Median/Mode) | Fill missing with central value | `df.fillna(df.mean())` |\n",
    "| Forward/Backward Fill | Fill with previous/next value | `df.fillna(method='ffill')` |\n",
    "| KNN / Regression Imputation | Predict missing values | `from sklearn.impute import KNNImputer` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfefa7",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Handling Duplicates\n",
    "\n",
    "Goal: Remove duplicate data to avoid bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89995e",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Handling Outliers\n",
    "\n",
    "Goal: Detect and handle abnormal data points.\n",
    "\n",
    "‚úÖ Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1513a",
   "metadata": {},
   "source": [
    "| Method | Description | Code Example |\n",
    "|--------|-------------|--------------|\n",
    "| IQR (Interquartile Range) | Values outside Q1 - 1.5 √ó IQR or Q3 + 1.5 √ó IQR | `df = df[(df[col] >= Q1 - 1.5*IQR) & (df[col] <= Q3 + 1.5*IQR)]` |\n",
    "| Z-Score Method | Remove data with \\|z-score\\| > 3 | `from scipy import stats`<br>`df = df[(np.abs(stats.zscore(df[col])) < 3)]` |\n",
    "| Visualization | Boxplot / Scatterplot | `sns.boxplot(data=df, x='feature')` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af3cb3",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ Encoding Categorical Data\n",
    "\n",
    "Goal: Convert categorical values into numeric format for ML models.\n",
    "\n",
    "‚úÖ Encoding Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ca56d",
   "metadata": {},
   "source": [
    "| Method | Use Case | Code Example |\n",
    "|--------|----------|--------------|\n",
    "| Label Encoding | Ordinal categories | `le = LabelEncoder()`<br>`df['size'] = le.fit_transform(df['size'])` |\n",
    "| One-Hot Encoding | Non-ordinal categories | `df_encoded = pd.get_dummies(df, columns=['color', 'city'])` |\n",
    "| Ordinal Encoding | Custom order | `size_map = {'S':1, 'M':2, 'L':3}`<br>`df['size_ord'] = df['size'].map(size_map)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37e1a8",
   "metadata": {},
   "source": [
    "### 7Ô∏è‚É£ Feature Scaling / Normalization\n",
    "\n",
    "Goal: Normalize feature range so all have equal importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcaa5b4",
   "metadata": {},
   "source": [
    "| Method | Description | Code Example |\n",
    "|--------|-------------|--------------|\n",
    "| Standardization (Z-score) | Mean = 0, SD = 1 | `scaler = StandardScaler()`<br>`X_scaled = scaler.fit_transform(X)` |\n",
    "| Min-Max Scaling | Range [0, 1] | `scaler = MinMaxScaler()`<br>`X_scaled = scaler.fit_transform(X)` |\n",
    "| Robust Scaling | Uses median/IQR | `scaler = RobustScaler()`<br>`X_scaled = scaler.fit_transform(X)` |\n",
    "| L2 Normalization | Scales to unit norm | `normalizer = Normalizer()`<br>`X_norm = normalizer.fit_transform(X)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4dfbc",
   "metadata": {},
   "source": [
    "### 8Ô∏è‚É£ Feature Transformation\n",
    "\n",
    "Goal: Make skewed data normal, or improve interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b9f41",
   "metadata": {},
   "source": [
    "| Method | Description | Code Example |\n",
    "|--------|-------------|--------------|\n",
    "| Log Transform | Reduces right skew | `df['log_feature'] = np.log1p(df['feature'])` |\n",
    "| Square Root / Power | Moderate skew | `df['sqrt_feature'] = np.sqrt(df['feature'])` |\n",
    "| Box-Cox / Yeo-Johnson | Advanced normalization | `pt = PowerTransformer(method='yeo-johnson')`<br>`df['transformed'] = pt.fit_transform(df[['feature']])` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627d6ed",
   "metadata": {},
   "source": [
    "### 9Ô∏è‚É£ Feature Engineering\n",
    "\n",
    "Goal: Create new informative features.\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total'] = df['A'] + df['B']\n",
    "df['Avg'] = df[['A', 'B', 'C']].mean(axis=1)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Is_Weekend'] = df['Date'].dt.dayofweek > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d61389",
   "metadata": {},
   "source": [
    "### üîü Feature Selection\n",
    "\n",
    "Goal: Select the most important features for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7d452",
   "metadata": {},
   "source": [
    "| Method | Description | Code Example |\n",
    "|--------|-------------|--------------|\n",
    "| Filter Methods | Correlation / Chi-square | `selector = SelectKBest(score_func=f_classif, k=10)`<br>`X_new = selector.fit_transform(X, y)` |\n",
    "| Wrapper Methods | Recursive Feature Elimination (RFE) | `rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)`<br>`X_rfe = rfe.fit_transform(X, y)` |\n",
    "| Embedded Methods | Lasso / Tree-based importance | `lasso = Lasso(alpha=0.01)`<br>`lasso.fit(X, y)`<br>`important_features = lasso.coef_ != 0` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb5706",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£1Ô∏è‚É£ Data Splitting\n",
    "\n",
    "Goal: Split dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4729cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00fa3f",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£2Ô∏è‚É£ Balancing Data (if imbalanced classes)\n",
    "\n",
    "Goal: Handle class imbalance in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa227d",
   "metadata": {},
   "source": [
    "| Method | Description | Code Example |\n",
    "|--------|-------------|--------------|\n",
    "| Oversampling (SMOTE) | Generate synthetic minority samples | `smote = SMOTE(random_state=42)`<br>`X_res, y_res = smote.fit_resample(X, y)` |\n",
    "| Undersampling | Remove majority samples | `undersampler = RandomUnderSampler(random_state=42)`<br>`X_res, y_res = undersampler.fit_resample(X, y)` |\n",
    "| Class Weights | Assign weight in training | `model = RandomForestClassifier(class_weight='balanced')`<br>`model.fit(X_train, y_train)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585ce0a",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£3Ô∏è‚É£ Data Pipeline Creation (Automation)\n",
    "\n",
    "Goal: Automate preprocessing using Scikit-learn Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['Age', 'Salary']\n",
    "categorical_features = ['Gender']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor)\n",
    "])\n",
    "\n",
    "X_preprocessed = pipeline.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e805224",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
