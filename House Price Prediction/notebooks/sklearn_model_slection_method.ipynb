{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3f888d",
   "metadata": {},
   "source": [
    "### sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522ad62",
   "metadata": {},
   "source": [
    "### 1) train_test_split\n",
    "\n",
    "What: Split arrays or DataFrames into random train and test subsets.\n",
    "When: Quick holdout split (baseline evaluation, debugging, simple experiments).\n",
    "\n",
    "Key args:\n",
    "\n",
    "1. test_size / train_size (float or int) — portion or absolute count.\n",
    "\n",
    "2. random_state — seed for reproducibility.\n",
    "\n",
    "3. shuffle — whether to shuffle before splitting (True by default).\n",
    "\n",
    "4. stratify — array to preserve class proportions (important for classification).\n",
    "\n",
    "Pitfalls: Don’t call on whole dataset including future samples (time series). Use stratify for imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a11d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22db0b7",
   "metadata": {},
   "source": [
    "### 2) KFold\n",
    "\n",
    "What: K-fold cross-validation splitter (no stratification). Splits data into n_splits consecutive folds.\n",
    "\n",
    "Key args:\n",
    "\n",
    "1. n_splits (default 5)\n",
    "\n",
    "2. shuffle — whether to shuffle before splitting (False by default)\n",
    "\n",
    "3. random_state — seed when shuffle=True\n",
    "\n",
    "When: Regression or when class balance across folds is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5acfc4",
   "metadata": {},
   "source": [
    "### 3) StratifiedKFold\n",
    "\n",
    "What: Like KFold, but preserves class proportions across folds (classification).\n",
    "\n",
    "When: Classification tasks with imbalanced classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac959ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for tr, val in skf.split(X, y):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcbb8f",
   "metadata": {},
   "source": [
    "### 4) GroupKFold\n",
    "\n",
    "What: Ensure samples from the same group (e.g., patient, user, store) are all in either train or test, never split.\n",
    "\n",
    "When: You have grouped data and want to avoid leakage between groups.\n",
    "\n",
    "Key arg: groups passed to .split(X, y, groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ed426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for tr, val in gkf.split(X, y, groups):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b5cd5",
   "metadata": {},
   "source": [
    "### 5) TimeSeriesSplit\n",
    "\n",
    "What: For time-series cross-validation. Produces forward-chaining splits: train indices up to time t, test indices after t.\n",
    "\n",
    "Key args: n_splits, max_train_size optional.\n",
    "\n",
    "When: Time series forecasting or data with temporal order.\n",
    "\n",
    "Pitfall: Do not shuffle! Keep chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for tr, val in tscv.split(X):\n",
    "    # tr < val in time\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5f87e",
   "metadata": {},
   "source": [
    "### 6) LeaveOneOut / LeavePOut\n",
    "\n",
    "What: Extreme CV: LOO leaves one sample out each iteration; LeavePOut leaves p samples out.\n",
    "\n",
    "When: Very small datasets (LOO). Expensive for large datasets.\n",
    "\n",
    "Example (LOO):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614acb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "for tr, val in loo.split(X):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3be32",
   "metadata": {},
   "source": [
    "### 7) ShuffleSplit / StratifiedShuffleSplit\n",
    "\n",
    "What: Repeated random train/test splits (randomized). Stratified version preserves class proportions.\n",
    "\n",
    "When: You want multiple random splits rather than contiguous folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "for tr, val in ss.split(X):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5349a0",
   "metadata": {},
   "source": [
    "### 8) RepeatedKFold / RepeatedStratifiedKFold\n",
    "\n",
    "What: Repeat KFold / StratifiedKFold multiple times with different shuffles (gives more stable estimate).\n",
    "\n",
    "Key args: n_repeats, random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07460a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596711f",
   "metadata": {},
   "source": [
    "### 9) PredefinedSplit\n",
    "\n",
    "What: Use a user-specified split array to indicate train/test fold membership (useful for custom CV split / temporal splitting).\n",
    "\n",
    "Example:\n",
    "If test_fold = [-1,-1,0,0,1,1], indices with -1 are training, others are test for folds 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1843f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "ps = PredefinedSplit(test_fold)\n",
    "cross_val_score(model, X, y, cv=ps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4f27b",
   "metadata": {},
   "source": [
    "### 10) cross_val_score\n",
    "\n",
    "What: Train estimator over cross-validation splits and return an array of scores.\n",
    "\n",
    "Key args:\n",
    "\n",
    "estimator, X, y, cv (int or splitter), scoring (string or callable), n_jobs, verbose, fit_params\n",
    "\n",
    "Returns: 1-D array of scores (one per CV split). For negative metrics like neg_root_mean_squared_error, you may invert sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80694f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "rmse = -scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178c848",
   "metadata": {},
   "source": [
    "### 11) cross_validate\n",
    "\n",
    "What: More flexible than cross_val_score. Can return multiple metrics, fit times, score times, and training scores.\n",
    "\n",
    "Key args:\n",
    "\n",
    "scoring can be a list/dict of metrics\n",
    "\n",
    "return_train_score=True if you want train metrics\n",
    "\n",
    "returns dict with keys like test_score, train_score, fit_time, score_time (and test_<scorename>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4855d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "res = cross_validate(pipe, X, y, cv=5, scoring=['r2','neg_root_mean_squared_error'], return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381fc12",
   "metadata": {},
   "source": [
    "### 12) cross_val_predict\n",
    "\n",
    "What: Generate cross-validated estimates for each input sample (out-of-fold predictions). Useful for stacking, blending, OOF predictions.\n",
    "\n",
    "Important: This returns predictions that are always made by models that did not see the sample during training (good for meta-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "oof_preds = cross_val_predict(pipe, X, y, cv=5, method='predict')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11faa040",
   "metadata": {},
   "source": [
    "### 13) GridSearchCV\n",
    "\n",
    "What: Exhaustive search over parameter grid with cross-validation. Selects best parameter combination.\n",
    "\n",
    "Key args:\n",
    "\n",
    "estimator, param_grid (dict: param names -> list), cv, scoring, n_jobs, refit (if True, fits best estimator on full data), verbose.\n",
    "\n",
    "Usage: Use estimator__param names for parameters inside pipelines.\n",
    "\n",
    "Pitfalls:\n",
    "\n",
    "Expensive for large grids.\n",
    "\n",
    "Use pre_dispatch, n_jobs.\n",
    "\n",
    "Use RandomizedSearchCV when grid is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'model__alpha': [0.1, 1.0, 10.0]}\n",
    "gs = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "best = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04e212",
   "metadata": {},
   "source": [
    "### 14) RandomizedSearchCV\n",
    "\n",
    "What: Sample parameter combinations from distributions (faster/cheap alternative to GridSearch).\n",
    "\n",
    "Key args: param_distributions (dict of distributions or lists), n_iter, cv, random_state.\n",
    "\n",
    "When: Large hyperparameter spaces or expensive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9802bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {'model__n_estimators': [100,300,500], 'model__max_depth': [3,5,7]}\n",
    "rs = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20, cv=5, n_jobs=-1, random_state=42)\n",
    "rs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4631e7",
   "metadata": {},
   "source": [
    "### 15) ParameterGrid / ParameterSampler\n",
    "\n",
    "What: Utility classes to create (grid) or sample (random) parameter combos for custom loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "grid = list(ParameterGrid({'a':[1,2], 'b':[True,False]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324136cb",
   "metadata": {},
   "source": [
    "### 16) permutation_test_score\n",
    "\n",
    "What: Statistical significance test for model score: shuffles labels to compute null distribution of the score. Returns observed score, permutation scores, p-value.\n",
    "\n",
    "When: Test if model performance is significantly different from chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "score, perm_scores, pvalue = permutation_test_score(model, X, y, scoring='accuracy', cv=5, n_permutations=100, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79bfc1",
   "metadata": {},
   "source": [
    "### 17) learning_curve\n",
    "\n",
    "What: Compute training and cross-validation scores for different training set sizes. Useful to diagnose bias/variance and whether more data helps.\n",
    "\n",
    "Key args: train_sizes, cv, scoring, n_jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(pipe, X, y, cv=5, train_sizes=np.linspace(0.1,1.0,5), scoring='neg_root_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c1b3c",
   "metadata": {},
   "source": [
    "### 18) validation_curve\n",
    "\n",
    "What: Evaluate model performance as a function of a single hyperparameter (useful for seeing under/overfitting behavior relative to a parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "param_range = [1,10,100,1000]\n",
    "train_scores, test_scores = validation_curve(Ridge(), X, y, param_name='alpha', param_range=param_range, cv=5, scoring='neg_root_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c14ee",
   "metadata": {},
   "source": [
    "### 19) check_cv (sklearn.utils.validation? usually internal)\n",
    "\n",
    "Note: Not a user-level common function; users choose CV splitters directly. Use cv=5 (int) for default KFold or pass splitter objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65df668",
   "metadata": {},
   "source": [
    "### 20) Choosing cv argument (int vs splitter)\n",
    "\n",
    "cv=int → use default splitter:\n",
    "\n",
    "classification → StratifiedKFold\n",
    "\n",
    "regression → KFold\n",
    "\n",
    "cv=splitter_object → pass any of the splitters above (KFold, TimeSeriesSplit, etc.)\n",
    "\n",
    "cv=PredefinedSplit → custom splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43bde7",
   "metadata": {},
   "source": [
    "### 21) scoring parameter\n",
    "\n",
    "Accepts strings (e.g., 'accuracy', 'roc_auc', 'neg_mean_squared_error') or a callable.\n",
    "\n",
    "For loss metrics where lower is better, sklearn often uses negative versions (neg_mean_squared_error) so cross_val_score returns higher-is-better numbers. Convert sign when interpreting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150eb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "rmse = -scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5accdd63",
   "metadata": {},
   "source": [
    "### 22) Parallelism & performance\n",
    "\n",
    "n_jobs=-1 to use all CPUs (useful for cross_val_score, GridSearchCV, etc.). Be mindful of memory.\n",
    "\n",
    "verbose useful for long runs.\n",
    "\n",
    "For nested parallelism (e.g., pipeline + grid search) prefer controlling n_jobs carefully to avoid oversubscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecc995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
